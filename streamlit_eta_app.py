
# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import re
from pathlib import Path

st.set_page_config(page_title="ETA ‚Äì Benchmark qualit√© (GTFS-rt)", layout="wide")

st.title("üöç ETA ‚Äì Qualit√© & Fiabilit√© (Benchmark)")
st.caption("Chargez votre fichier (CSV/XLSX) avec les colonnes: agency, route, bucket, source, Early, Late, Accurate, Predictions")

# ------------------------------
# Sidebar ‚Äì param√®tres & filtres
# ------------------------------
with st.sidebar:
    st.header("Param√®tres d'analyse")
    st.markdown("**1) Fichier & filtres de base**")

uploaded = st.file_uploader("D√©posez un fichier .csv ou .xlsx", type=["csv","xlsx"])   
use_default = st.checkbox("Utiliser le fichier local par d√©faut: accuracy_general_literal.csv (s'il existe)")

EXPECTED_COLS = {"agency","route","bucket","source","Early","Late","Accurate","Predictions"}
BUCKETS_DEFAULT = ["0 - 3 min","3 - 6 min","6 - 10 min","10 - 15 min"]

# --- Helpers ---

def _standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Standardise les colonnes et types, corrige les espaces/variantes d'√©criture.
    (Corrige le bug 'Series' has no attribute strip en utilisant .str.strip())"""
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    missing = EXPECTED_COLS - set(df.columns)
    if missing:
        raise ValueError(f"Colonnes manquantes: {', '.join(sorted(missing))}")
    # Types num√©riques
    for col in ["Early","Late","Accurate","Predictions"]:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    # Types texte
    df['route']  = df['route'].astype(str)
    df['bucket'] = df['bucket'].astype(str).str.strip()
    df['agency'] = df['agency'].astype(str).str.strip()
    df['source'] = df['source'].astype(str).str.strip()
    # Normalisation des buckets: unifier tirets/espaces
    def norm_bucket(val: str) -> str:
        s = (val or '').strip()
        s = s.replace('‚Äì','-').replace('‚Äî','-')
        s = re.sub(r"\s*-\s*", " - ", s)
        return s
    df['bucket'] = df['bucket'].map(norm_bucket)
    # Nettoyage basique
    df = df.dropna(subset=["Early","Late","Accurate","Predictions"]) 
    return df

@st.cache_data(show_spinner=False)
def _load_df(file):
    """Accepte un fichier upload√© (Streamlit) OU un chemin local (Path/str)."""
    if file is None:
        return None
    # Chemin local
    if isinstance(file, (str, Path)):
        p = Path(file)
        if p.suffix.lower() == '.csv':
            df = pd.read_csv(p)
        else:
            df = pd.read_excel(p)
        return _standardize_columns(df)
    # Fichier upload√©
    name = getattr(file, 'name', '').lower()
    if name.endswith('.csv'):
        df = pd.read_csv(file)
    else:
        df = pd.read_excel(file)
    return _standardize_columns(df)


def weighted_avg(values, weights):
    v = np.asarray(values)
    w = np.asarray(weights)
    if np.nansum(w) == 0:
        return np.nan
    return np.average(v, weights=w)

# ---------- Chargement des donn√©es ----------

if uploaded is not None:
    try:
        df = _load_df(uploaded)
    except Exception as e:
        st.error(str(e))
        st.stop()
elif use_default:
    demo_path = Path('accuracy_general_literal.csv')
    if demo_path.exists():
        try:
            df = _load_df(demo_path)
            st.info("Fichier par d√©faut charg√©: accuracy_general_literal.csv")
        except Exception as e:
            st.error(str(e))
            st.stop()
    else:
        st.warning("Le fichier par d√©faut n'est pas pr√©sent dans le r√©pertoire de l'app. Veuillez en t√©l√©verser un.")
        st.stop()
else:
    st.info("Chargez un fichier pour lancer l'analyse, ou cochez l'option fichier par d√©faut si disponible.")
    st.stop()

# --------- Filtres dynamiques ---------
with st.sidebar:
    st.markdown("**2) Filtres**")
    agencies = sorted(df['agency'].dropna().unique().tolist())
    sources = sorted(df['source'].dropna().unique().tolist())
    buckets_all = [b for b in BUCKETS_DEFAULT if b in df['bucket'].unique()]

    agency_sel = st.multiselect("Agence(s)", agencies, default=agencies)
    source_sel = st.multiselect("Source(s)", sources, default=sources)
    buckets_sel = st.multiselect("Horizon(s) inclus pour les KPIs", buckets_all, default=buckets_all)

    st.markdown("**Filtre lignes**")
    route_filter = st.text_input("Contient / Regex (ex: ^[1-9]\\d*$ pour num√©riques)", value="")
    cand_routes = df['route'].unique().tolist()
    if route_filter.strip():
        try:
            pattern = re.compile(route_filter.strip())
            cand_routes = [r for r in cand_routes if pattern.search(r)]
        except Exception:
            cand_routes = [r for r in cand_routes if route_filter.strip().lower() in r.lower()]
    cand_routes = sorted(cand_routes, key=lambda x: (len(x), x))
    route_sel = st.multiselect("Ligne(s)", cand_routes, default=cand_routes)

    st.markdown("**Seuils & affichage**")
    thresh = st.number_input("Seuil min. de volume Top/Bottom (Predictions)", min_value=0, value=300_000, step=50_000, format="%d")
    show_n = st.slider("Nombre de lignes √† afficher (Top & Bottom)", min_value=5, max_value=20, value=10, step=1)

# Appliquer filtres
filt = df[df['agency'].isin(agency_sel) & df['source'].isin(source_sel) & df['route'].isin(route_sel)].copy()

# ---------------------
# Calculs des indicateurs
# ---------------------
rows = filt[filt['bucket'].isin(buckets_sel)].copy()

if rows.empty:
    st.warning("Aucune donn√©e apr√®s application des filtres.")
    st.stop()

overall = {
    'Early_%': weighted_avg(rows['Early'], rows['Predictions']),
    'Late_%': weighted_avg(rows['Late'], rows['Predictions']),
    'Accurate_%': weighted_avg(rows['Accurate'], rows['Predictions']),
    'Predictions': rows['Predictions'].sum()
}

by_bucket = (
    rows.groupby('bucket').apply(lambda g: pd.Series({
        'Early_%': weighted_avg(g['Early'], g['Predictions']),
        'Late_%': weighted_avg(g['Late'], g['Predictions']),
        'Accurate_%': weighted_avg(g['Accurate'], g['Predictions']),
        'Predictions': g['Predictions'].sum()
    })).reset_index()
)

overall_rows = filt[filt['bucket']=="Overall average: Equally Weighted Predictions"][['agency','route','source','Early','Late','Accurate','Predictions']].copy()
if overall_rows.empty:
    agg = rows.groupby(['agency','route','source']).apply(lambda g: pd.Series({
        'Early': weighted_avg(g['Early'], g['Predictions']),
        'Late': weighted_avg(g['Late'], g['Predictions']),
        'Accurate': weighted_avg(g['Accurate'], g['Predictions']),
        'Predictions': g['Predictions'].sum()
    })).reset_index()
    overall_rows = agg

# -----------------
# Tuiles KPI globales
# -----------------
c1, c2, c3, c4 = st.columns(4)
c1.metric("% Pr√©cises (pond√©r√©)", f"{overall['Accurate_%']:.1f}%")
c2.metric("% En avance (pond√©r√©)", f"{overall['Early_%']:.1f}%")
c3.metric("% En retard (pond√©r√©)", f"{overall['Late_%']:.1f}%")
c4.metric("Volume de pr√©dictions", f"{overall['Predictions']:,}")

st.divider()

# -----------------
# Visuel par bucket
# -----------------
st.subheader("Par horizon/bucket")
order = [b for b in BUCKETS_DEFAULT if b in by_bucket['bucket'].unique()]
by_bucket['bucket'] = pd.Categorical(by_bucket['bucket'], categories=order, ordered=True)
by_bucket = by_bucket.sort_values('bucket')

chart_df = by_bucket.melt(id_vars=['bucket','Predictions'], value_vars=['Accurate_%','Early_%','Late_%'], var_name='Type', value_name='Pourcentage')
chart_df['Type'] = chart_df['Type'].map({'Accurate_%':'Pr√©cis','Early_%':'En avance','Late_%':'En retard'})

line = (
    alt.Chart(chart_df)
    .mark_line(point=True)
    .encode(
        x=alt.X('bucket:N', title='Horizon avant arriv√©e'),
        y=alt.Y('Pourcentage:Q', title='Pourcentage pond√©r√©', scale=alt.Scale(domain=[0,100])),
        color=alt.Color('Type:N', title='Cat√©gorie', scale=alt.Scale(range=['#2ca02c','#1f77b4','#d62728'])),
        tooltip=['bucket','Type',alt.Tooltip('Pourcentage:Q', format='.1f'),'Predictions']
    ).properties(height=300)
)
st.altair_chart(line, use_container_width=True)

st.dataframe(by_bucket.rename(columns={'bucket':'Bucket','Accurate_%':'% Pr√©cis','Early_%':'% En avance','Late_%':'% En retard','Predictions':'Pr√©dictions'}), use_container_width=True)

st.divider()

# --------------------------------------
# Visuel comparatif Top/Bottom (empil√©)
# --------------------------------------
st.subheader("Comparatif Top / Bottom (‚â• seuil de volume)")

def clean_route(x):
    try:
        f = float(x)
        if f.is_integer():
            return str(int(f))
        return str(x)
    except:
        return str(x)

hi = overall_rows[overall_rows['Predictions']>=thresh].copy()
hi['route_display'] = hi['route'].apply(clean_route)

topN = hi.sort_values('Accurate', ascending=False).head(show_n)
botN = hi.sort_values('Accurate', ascending=True).head(show_n)

st.caption(f"{hi['route'].nunique()} lignes passent le seuil (sur {overall_rows['route'].nunique()} lignes filtr√©es). Seuil = {thresh:,} pr√©dictions.")

def stacked_bar(df_in, title):
    if df_in.empty:
        return alt.Chart(pd.DataFrame({'x':[0]})).mark_text(text='Aucune ligne au-dessus du seuil').properties(title=title)
    d = df_in.copy()
    d = d.rename(columns={'route_display':'Ligne','Accurate':'Pr√©cis','Early':'En avance','Late':'En retard'})
    d = d.melt(id_vars=['Ligne','Predictions'], value_vars=['Pr√©cis','En avance','En retard'], var_name='Type', value_name='Pourcentage')
    chart = (
        alt.Chart(d)
        .mark_bar()
        .encode(
            y=alt.Y('Ligne:N', sort='-x', title='Ligne'),
            x=alt.X('Pourcentage:Q', title='Pourcentage (%)', scale=alt.Scale(domain=[0,100])),
            color=alt.Color('Type:N', scale=alt.Scale(range=['#2ca02c','#1f77b4','#d62728'])),
            tooltip=['Ligne','Type',alt.Tooltip('Pourcentage:Q', format='.1f'),'Predictions']
        )
        .properties(title=title, height=300)
    )
    return chart

c5, c6 = st.columns(2)
with c5:
    st.altair_chart(stacked_bar(topN, 'Top lignes ‚Äì composition ETA (%)'), use_container_width=True)
with c6:
    st.altair_chart(stacked_bar(botN, 'Bottom lignes ‚Äì composition ETA (%)'), use_container_width=True)

st.divider()

# -----------------------------------------------------
# Scatter: % Pr√©cis vs % En avance (taille = volume)
# -----------------------------------------------------
st.subheader("Dispersion des lignes (pond√©r√©)")
scatter_df = hi.copy()
scatter_df = scatter_df.rename(columns={'route_display':'Ligne'})
bubble = (
    alt.Chart(scatter_df)
    .mark_circle(opacity=0.7)
    .encode(
        x=alt.X('Early:Q', title='% En avance', scale=alt.Scale(domain=[0, max(5, float(scatter_df['Early'].max())+5)])),
        y=alt.Y('Accurate:Q', title='% Pr√©cis', scale=alt.Scale(domain=[0, 100])),
        size=alt.Size('Predictions:Q', title='Volume pr√©dictions', scale=alt.Scale(range=[20, 800])),
        color=alt.Color('agency:N', title='Agence'),
        tooltip=['Ligne','agency','source',alt.Tooltip('Accurate:Q', format='.1f'),alt.Tooltip('Early:Q', format='.1f'),alt.Tooltip('Late:Q', format='.1f'),'Predictions']
    )
    .properties(height=380)
    .interactive()
)
st.altair_chart(bubble, use_container_width=True)

st.divider()

# -----------------------------------------------------
# Profil d'une ligne s√©lectionn√©e ‚Äì par bucket
# -----------------------------------------------------
st.subheader("Profil d√©taill√© d'une ligne par horizon")
selectable_routes = sorted(rows['route'].unique().tolist(), key=lambda x: (len(x), x))
route_focus = st.selectbox("Choisir une ligne", options=selectable_routes)

prof = rows[rows['route']==route_focus].copy()
if not prof.empty:
    prof['bucket'] = pd.Categorical(prof['bucket'], categories=order, ordered=True)
    prof = prof.sort_values('bucket')
    prof_long = prof.melt(id_vars=['bucket','Predictions'], value_vars=['Accurate','Early','Late'], var_name='Type', value_name='Pourcentage')
    prof_long['Type'] = prof_long['Type'].map({'Accurate':'Pr√©cis','Early':'En avance','Late':'En retard'})
    bar_prof = (
        alt.Chart(prof_long)
        .mark_bar()
        .encode(
            x=alt.X('bucket:N', title='Horizon'),
            y=alt.Y('Pourcentage:Q', title='Pourcentage (%)', scale=alt.Scale(domain=[0,100])),
            color=alt.Color('Type:N', scale=alt.Scale(range=['#2ca02c','#1f77b4','#d62728'])),
            tooltip=['bucket','Type',alt.Tooltip('Pourcentage:Q', format='.1f'),'Predictions']
        )
        .properties(title=f"Ligne {route_focus} ‚Äì composition par horizon", height=320)
    )
    st.altair_chart(bar_prof, use_container_width=True)
else:
    st.info("Aucune donn√©e par bucket pour cette ligne avec les filtres actuels.")

st.divider()

# -------------------------------
# T√©l√©chargements des jeux de donn√©es
# -------------------------------
st.subheader("Donn√©es d√©taill√©es ‚Äì t√©l√©chargement")

overall_dl = overall_rows[['agency','route','source','Early','Late','Accurate','Predictions']].copy().sort_values('route')
st.download_button(
    label="T√©l√©charger ‚Äì Overall par ligne (CSV)",
    data=overall_dl.to_csv(index=False).encode('utf-8'),
    file_name='overall_by_route.csv',
    mime='text/csv'
)

buckets_rows = rows.copy()
st.download_button(
    label="T√©l√©charger ‚Äì Par horizon / par ligne (CSV)",
    data=buckets_rows.to_csv(index=False).encode('utf-8'),
    file_name='by_horizon_by_route.csv',
    mime='text/csv'
)
